{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install cognite-sdk: \n",
    "\n",
    "```pip install cognite-sdk```\n",
    "\n",
    "While were at it we might also want to download ```msal``` which we will use later. (Microsoft Authentication Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Authentication through OIDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import os\n",
    "\n",
    "from cognite.client import CogniteClient\n",
    "from msal import PublicClientApplication, SerializableTokenCache\n",
    "\n",
    "# Contact Project Administrator to get these\n",
    "TENANT_ID = \"20d3c681-9982-4395-abd6-7973f7e0f26a\"\n",
    "CLIENT_ID = \"7ee73a81-b136-404c-bccc-6f73047d88b0\"\n",
    "CDF_CLUSTER = \"az-power-no-northeurope\"  # api, westeurope-1 etc\n",
    "COGNITE_PROJECT = \"heco-dev\"\n",
    "\n",
    "CACHE_FILENAME = \"cache.bin\"\n",
    "SCOPES = [f\"https://{CDF_CLUSTER}.cognitedata.com/.default\"]\n",
    "\n",
    "AUTHORITY_HOST_URI = \"https://login.microsoftonline.com\"\n",
    "AUTHORITY_URI = AUTHORITY_HOST_URI + \"/\" + TENANT_ID\n",
    "PORT = 53000\n",
    "\n",
    "\n",
    "def create_cache():\n",
    "    cache = SerializableTokenCache()\n",
    "    if os.path.exists(CACHE_FILENAME):\n",
    "        cache.deserialize(open(CACHE_FILENAME, \"r\").read())\n",
    "    atexit.register(lambda:\n",
    "        open(CACHE_FILENAME, \"w\").write(cache.serialize()) if cache.has_state_changed else None\n",
    "    )\n",
    "    return cache\n",
    "\n",
    "\n",
    "def authenticate_azure(app):\n",
    "    # Firstly, check the cache to see if this end user has signed in before\n",
    "    accounts = app.get_accounts()\n",
    "    if accounts:\n",
    "        creds = app.acquire_token_silent(SCOPES, account=accounts[0])\n",
    "    else:\n",
    "        # interactive login - make sure you have http://localhost:port in Redirect URI in App Registration as type \"Mobile and desktop applications\"\n",
    "        creds = app.acquire_token_interactive(scopes=SCOPES, port=PORT,)\n",
    "\n",
    "    return creds\n",
    "\n",
    "\n",
    "app = PublicClientApplication(client_id=CLIENT_ID, authority=AUTHORITY_URI, token_cache=create_cache())\n",
    "\n",
    "\n",
    "def get_token():\n",
    "    return authenticate_azure(app)[\"access_token\"]\n",
    "\n",
    "\n",
    "client = CogniteClient(\n",
    "    token_url=f\"{AUTHORITY_URI}/v2.0\",\n",
    "    token=get_token,\n",
    "    token_client_id=CLIENT_ID,\n",
    "    project=COGNITE_PROJECT,\n",
    "    base_url=f\"https://{CDF_CLUSTER}.cognitedata.com\",\n",
    "    client_name=\"cognite-python-dev\",\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "print(client.iam.token.inspect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.time_series.list(limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Authentication with API-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client import CogniteClient\n",
    "from getpass import getpass\n",
    "\n",
    "client_google = CogniteClient(\n",
    "    api_key = getpass(\"API KEY:\"),\n",
    "    project = \"heco-prod\",\n",
    "    base_url = \"https://power-no.cognitedata.com/\",\n",
    "    client_name = \"edvard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_google.sequences.list(limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Listing things\n",
    "\n",
    "There is one separate function for listing each data type in CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.time_series.list()\n",
    "client.assets.list()\n",
    "client.sequences.list()\n",
    "client.events.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list functions lets you be very selective about what data you are searching for. (Show full list of parameters in API documentation)\n",
    "\n",
    "Let us see how some of the parameters work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"unit\" if i for example know that my time_series uses m3/s then I can find those time series by writing\n",
    "client.time_series.list(unit=\"m3/s\")\n",
    "\n",
    "# Each CDF project has many datasets within them, used to sort data. Maybe I know that what I am looking for is in a specific dataset\n",
    "client.time_series.list(unit=\"m3/s\",data_set_external_ids=[\"uc:001:shop\"])\n",
    "\n",
    "# Or I might know the time range in which the time-series was created\n",
    "from cognite.client.data_classes.shared import TimestampRange\n",
    "from datetime import datetime\n",
    "\n",
    "client.time_series.list(\n",
    "    unit=\"m3/s\",\n",
    "    data_set_external_ids=[\"uc:001:shop\"],\n",
    "    created_time=TimestampRange(\n",
    "        min = datetime(2022,5,1,0).timestamp()*1000, # CDF uses timestamps in milliseconds since 1970,jan 1, 00:00\n",
    "        max = datetime(2022,5,3,0).timestamp()*1000\n",
    "    )\n",
    ")\n",
    "\n",
    "# The limit parameter sets how many matches you want to be returned, so if I for example only want the first 5 matches I would write\n",
    "client.time_series.list(\n",
    "    unit=\"m3/s\",\n",
    "    data_set_external_ids=[\"uc:001:shop\"],\n",
    "    created_time=TimestampRange(\n",
    "        min = datetime(2022,5,1,0).timestamp()*1000, # CDF uses timestamps in milliseconds since 1970,jan 1, 00:00\n",
    "        max = datetime(2022,5,3,0).timestamp()*1000\n",
    "    ),\n",
    "    limit = 5\n",
    ")\n",
    "\n",
    "# The reason why I am mentioning this up front, is that the limit parameter has a default value of 25,\n",
    "# thus if you want to fetch more than 25 elements you need to specify the limit of set it to None to get all elements\n",
    "client.time_series.list(\n",
    "    unit=\"m3/s\",\n",
    "    data_set_external_ids=[\"uc:001:shop\"],\n",
    "    created_time=TimestampRange(\n",
    "        min = datetime(2022,5,1,0).timestamp()*1000, # CDF uses timestamps in milliseconds since 1970,jan 1, 00:00\n",
    "        max = datetime(2022,5,3,0).timestamp()*1000\n",
    "    ),\n",
    "    limit = -1\n",
    ")\n",
    "\n",
    "# There may be situations where you already know what you are looking for and just want to fetch the information about that\n",
    "# specific element, we can then use the retrieve function instead of the list function to get those specific elements\n",
    "client.time_series.retrieve(external_id=\"/Begna/Kraftverk/FASL-Plan-MW-bp\")\n",
    "# The retrieve function takes in either an external id or internal id (which is often referred to as just id). I recommend\n",
    "# that you always use external ids, an will not really go into here why they both exists, I just wanted you to be aware\n",
    "# that there is another way to refer to specific data objects.\n",
    "\n",
    "# Final note, if you ever want to find time-series for which you are not completely sure of its properties it might be better to use the Fusion UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now want to look a bit at the elements which are listed\n",
    "listed_items = client.time_series.list(\n",
    "    unit=\"m3/s\",\n",
    "    data_set_external_ids=[\"uc:001:shop\"],\n",
    "    created_time=TimestampRange(\n",
    "        min = datetime(2022,5,1,0).timestamp()*1000, # CDF uses timestamps in milliseconds since 1970,jan 1, 00:00:00 UTC\n",
    "        max = datetime(2022,5,3,0).timestamp()*1000  # while .timestamp() gives milliseconds.\n",
    "    ),\n",
    "    limit = 1\n",
    ")\n",
    "\n",
    "listed_items[0]\n",
    "\n",
    "# We can see that we have a lot of information about the time series, but where is the data itself?\n",
    "\n",
    "# For \"sequences\" and \"time-series\", simply listing or retrieving an object doesn't retrieve the data it contains, instead it only contains \n",
    "# information about each of the objects. This reason for this, is that it is very inefficient to fetch millions of data-points just to see\n",
    "# what time_series exists.\n",
    "\n",
    "# I will start by showing you how we can retrieve the data of the time-series we just listed\n",
    "client.datapoints.retrieve(external_id=listed_items[0].external_id,start=datetime(2022,1,1,0),end=\"now\")\n",
    "\n",
    "# Easier to work with as a pandas dateframe so we could do\n",
    "client.datapoints.retrieve(external_id=listed_items[0].external_id,start=datetime(2022,1,1,0),end=\"now\").to_pandas()\n",
    "\n",
    "# Or we could have just worked with the list of datapoints directly\n",
    "# For example heres how you can access the values and timestamps of the retrieved datapoints separately\n",
    "datapoints = client.datapoints.retrieve(external_id=listed_items[0].external_id,start=datetime(2022,1,1,0),end=\"now\")\n",
    "values = datapoints.value\n",
    "timestamps = datapoints.timestamp\n",
    "\n",
    "print(values,timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In many situations there may be far more datapoints in a period than we need, to reduce the number of datapoints we can therefore use agregates\n",
    "\n",
    "# Say for example that I only want one datapoint per day then I could write:\n",
    "client.datapoints.retrieve(external_id=listed_items[0].external_id,start=datetime(2022,1,1,0),end=\"now\",granularity=\"1d\",aggregates=[\"average\"])\n",
    "\n",
    "# could also have used max or min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving a sequence is very similar to how time-series are retrieved\n",
    "client.sequences.data.retrieve_dataframe(external_id=\"SHOP_OE_base_mapping\",start = 0, end = -1) # start = 0 indicates that I want everything from the first row\n",
    "\n",
    "# Or I could fetch just the first 5 rows\n",
    "client.sequences.data.retrieve_dataframe(external_id=\"SHOP_OE_base_mapping\",start = 0, end = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to show you one of the very unique capabilities that make CDF very good for working with real world data\n",
    "# that is: Relationships.\n",
    "\n",
    "# I said earlier that CDF maintains the relationships between data, and the way it does this is with this special data-type called \"relationships\"\n",
    "\n",
    "# Show this for sequences in CDF, but this could for example also be a time-series which is linked to a specific asset, or as I show here\n",
    "# we can show that this plant has these generators.\n",
    "\n",
    "# Relationships can also be accessed easily through the API. Let's do it here for an event\n",
    "client.relationships.list(source_external_ids=[\"POWEROPS_SHOP_RUN_1651485019415\"]).to_pandas()[\"targetExternalId\"][0]\n",
    "\n",
    "# See the type of relationship from the label\n",
    "client.relationships.list(target_external_ids=[\"POWEROPS_SHOP_RUN_1651485019415\"]).to_pandas()[\"labels\"][1]\n",
    "\n",
    "client.relationships.list(target_external_ids=[\"SHOP_OE_incremental_mapping_multi_scenario_20_scenario_19_1651485012082\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data to CDF\n",
    "\n",
    "from cognite.client.data_classes import Sequence, TimeSeries\n",
    "import pandas as pd\n",
    "\n",
    "# Let us see how to create a sequence in CDF\n",
    "\n",
    "# First need to find some data which we want to upload\n",
    "column_def = [\n",
    "    {\n",
    "        \"valueType\":\"LONG\",\n",
    "        \"externalId\":\"user-number\",\n",
    "        \"description\":\"Unique ID\"\n",
    "    }, \n",
    "    {\n",
    "        \"valueType\":\"String\",\n",
    "        \"externalId\":\"user-name\",\n",
    "        \"description\":\"User\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data = [\n",
    "        [45345,\"Edvard\"],\n",
    "        [23523,\"Jørgen\"],\n",
    "        [345,\"Hauk\"],\n",
    "        [3626,\"Ole\"]\n",
    "    ],\n",
    "    columns=[\"user-number\",\"user-name\"]\n",
    ")\n",
    "\n",
    "# Create the sequence, first we only give create a sequence with the column headers\n",
    "client.sequences.create(\n",
    "    Sequence(\n",
    "        name = \"My dummy sequence\",\n",
    "        external_id=\"my_sequence\", \n",
    "        columns=column_def,\n",
    "        data_set_id=client.data_sets.retrieve(external_id=\"uc:001:shop\").id\n",
    "    )\n",
    ")\n",
    "# Show what happens if the external_id already exists, by running code again\n",
    "\n",
    "# Insert the data into the sequence, like to use dataframe as it is simple to work with.\n",
    "client.sequences.data.insert_dataframe(dataframe=df, external_id=\"my_sequence\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Can add some more rows, by downloading adding new rows and then reuploading\n",
    "downloaded_df = client.sequences.data.retrieve_dataframe(\n",
    "    external_id = \"my_sequence\",\n",
    "    start=0,\n",
    "    end=-1\n",
    ")\n",
    "\n",
    "downloaded_df.loc[4] = [21341324,\"Peder\"]\n",
    "downloaded_df.loc[5] = [2134324,\"Stina\"]\n",
    "\n",
    "client.sequences.data.insert_dataframe(dataframe=downloaded_df, external_id=\"my_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time-series\n",
    "client.time_series.create(\n",
    "    TimeSeries(\n",
    "        name=\"Meeting attendance\",\n",
    "        external_id=\"meeting_attendance\",\n",
    "        data_set_id=client.data_sets.retrieve(external_id=\"uc:001:shop\").id,\n",
    "        unit=\"people\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert datapoints into time series\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Tuple of datetime and value, remember time is given in UTC\n",
    "datapoints = [\n",
    "    (datetime(2022,6,20,9), 0),\n",
    "    (datetime(2022,6,20,9,58), 5),\n",
    "    (datetime(2022,6,20,10), 30),\n",
    "    (datetime(2022,6,20,10,50), 24),\n",
    "    (datetime(2022,6,20,11,50), 0),\n",
    "]   \n",
    "\n",
    "client.datapoints.insert(datapoints, external_id=\"meeting_attendance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a relationships between the data we have created\n",
    "\n",
    "from cognite.client.data_classes import Relationship\n",
    "\n",
    "ts_seq_relationship = Relationship(\n",
    "    external_id=\"ts_seq_relationship\",\n",
    "    source_external_id=\"meeting_attendance\",\n",
    "    source_type=\"timeseries\",\n",
    "    target_external_id=\"my_sequence\",\n",
    "    target_type=\"sequence\",\n",
    "    data_set_id=client.data_sets.retrieve(external_id=\"uc:001:shop\").id,\n",
    ")\n",
    "\n",
    "client.relationships.create([ts_seq_relationship])\n",
    "\n",
    "# Use Fusion UI to see the relationship\n",
    "\n",
    "# We could also have put a label on this relationship to explain what type of relationship it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the data we created, as we do not want it to clutter the real data in the CDF project\n",
    "\n",
    "# Be very careful with deleting data as you might end up deleting data which you did not intend to\n",
    "\n",
    "# Deleting specific rows of a sequence\n",
    "client.sequences.data.delete(external_id=\"my_sequence\", rows=[1,2,3])\n",
    "\n",
    "# Deleting specific datapoints of a timeseries\n",
    "client.datapoints.delete_range(start=datetime(2022,6,20,10,30), end=datetime(2022,6,20,14,50), external_id=\"meeting_attendance\")\n",
    "\n",
    "# Each datatype has its own delete function\n",
    "client.relationships.delete(external_id=\"ts_seq_relationship\")\n",
    "\n",
    "client.time_series.delete(external_id=\"meeting_attendance\")\n",
    "\n",
    "client.sequences.delete(external_id=\"my_sequence\")\n",
    "\n",
    "# Remember to delete relationship!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
